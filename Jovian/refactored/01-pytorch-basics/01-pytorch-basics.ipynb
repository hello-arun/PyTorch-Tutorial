{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics: Tensors & Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers the following topics:\n",
    "\n",
    "* Introductions to PyTorch tensors\n",
    "* Tensor operations and gradients\n",
    "* Interoperability between PyTorch and Numpy\n",
    "* How to use the PyTorch documentation site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the `torch` module to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with number, vector, matrix and 3D-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.) torch.float32\n",
      "tensor([1., 2., 3., 4.]) torch.float32\n",
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]]) torch.float32\n",
      "tensor([[[11., 12., 13.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[15., 16., 17.],\n",
      "         [17., 18., 19.]]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor(4.)            # Number\n",
    "t2 = torch.tensor([1., 2, 3, 4]) # Vector\n",
    "t3 = torch.tensor([[5., 6], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])     # Matrix\n",
    "# 3-dimensional array\n",
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.]]])            # 3D-Array\n",
    "print(t1,t1.dtype)\n",
    "print(t2,t2.dtype)\n",
    "print(t3,t3.dtype)\n",
    "print(t4,t4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([4]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t1.shape,t2.shape,t3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's not possible to create tensors with an improper shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will throw error if you run\n",
    "# t5 = torch.tensor([[5., 6, 11], \n",
    "#                    [7, 8], \n",
    "#                    [9, 10]])\n",
    "# t5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations and gradients\n",
    "\n",
    "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment. Let's create a new tensor `y` by combining these tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
    "\n",
    "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives of `y` with respect to all the input tensors are stored in the `.grad` property of the respective tensors. i.e (w and b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor functions\n",
    "\n",
    "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[42, 42],\n",
       "         [42, 42],\n",
       "         [42, 42]]),\n",
       " tensor([[ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.],\n",
       "         [42., 42.],\n",
       "         [42., 42.],\n",
       "         [42., 42.]]),\n",
       " tensor([[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894],\n",
       "         [ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]),\n",
       " tensor([[[-0.9589, -0.2794],\n",
       "          [ 0.6570,  0.9894]],\n",
       " \n",
       "         [[ 0.4121, -0.5440],\n",
       "          [-0.9165, -0.9165]],\n",
       " \n",
       "         [[-0.9165, -0.9165],\n",
       "          [-0.9165, -0.9165]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6 = torch.full((3, 2), 42) # Create a tensor with a fixed value for every element\n",
    "t7 = torch.cat((t3, t6)) # Concatenate two tensors with compatible shapes\n",
    "t8 = torch.sin(t7) # Compute the sin of each element\n",
    "t9 = t8.reshape(-1, 2, 2) # Change the shape of a tensor\n",
    "t6,t7,t8,t9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]),\n",
       " tensor([[[ 0,  1],\n",
       "          [ 2,  3],\n",
       "          [ 4,  5],\n",
       "          [ 6,  7],\n",
       "          [ 8,  9]],\n",
       " \n",
       "         [[10, 11],\n",
       "          [12, 13],\n",
       "          [14, 15],\n",
       "          [16, 17],\n",
       "          [18, 19]]]),\n",
       " tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t10=torch.arange(20)\n",
    "t10_rs=t10.reshape(2,5,2)\n",
    "t10_rs_rs=t10_rs.reshape(5,4)\n",
    "t10,t10_rs,t10_rs_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with Numpy\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we create an array in Numpy and transform it to torch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2.],\n",
       "        [3., 4.]]),\n",
       " tensor([[1., 2.],\n",
       "         [3., 4.]], dtype=torch.float64),\n",
       " array([[1., 2.],\n",
       "        [3., 4.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]]) # numpy array creation\n",
    "y = torch.from_numpy(x) # get torch tensor from the numpy array.\n",
    "z = y.numpy() # get back to numpy array\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `from_numpy()` method do not create a new copy of the data. It just access the same numpy array and treat it as torch tensor. So any change in original numpy array will reflect also in the torch tensor and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2.],\n",
       "        [1., 4.]]),\n",
       " tensor([[1., 2.],\n",
       "         [1., 4.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0]=1\n",
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
    "\n",
    "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
    "\n",
    "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
    "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
    "\n",
    "We'll leverage both these features of PyTorch extensively in this tutorial series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "Try out this assignment to learn more about tensor operations in PyTorch: https://jovian.ai/aakashns/01-tensor-operations\n",
    "\n",
    "\n",
    "This tutorial covers the following topics:\n",
    "\n",
    "* Introductions to PyTorch tensors\n",
    "* Tensor operations and gradients\n",
    "* Interoperability between PyTorch and Numpy\n",
    "\n",
    "\n",
    "You can learn more about PyTorch tensors here: https://pytorch.org/docs/stable/tensors.html. \n",
    "\n",
    "\n",
    "The material in this series is inspired by:\n",
    "\n",
    "* [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi \n",
    "* [FastAI development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) by Jeremy Howard. \n",
    "\n",
    "With this, we complete our discussion of tensors and gradients in PyTorch, and we're ready to move on to the next topic: [Gradient Descent & Linear Regression](https://jovian.ai/aakashns/02-linear-regression)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "84d952cebb2bbbce425367d3afc0182ffd63b5648e790ae44162e707a622c992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
